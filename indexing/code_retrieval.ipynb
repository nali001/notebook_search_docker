{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code retrieval using Haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAISS_INDEX_DIR = './code_faiss_indexes'\n",
    "\n",
    "EMBEDDING_MODELS = [(\"model1\", \"microsoft/codebert-base\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-built index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = EMBEDDING_MODELS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/vre/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# Load index\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "index_path=f\"{FAISS_INDEX_DIR}/{embedding_model[0]}/index.faiss\"\n",
    "config_path=f\"{FAISS_INDEX_DIR}/{embedding_model[0]}/config.json\"\n",
    "document_store = FAISSDocumentStore.load(index_path=index_path, config_path=config_path)\n",
    "\n",
    "# Check if the DocumentStore is loaded correctly\n",
    "assert document_store.faiss_index_factory_str == \"Flat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3711, 3711)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.get_document_count(), document_store.get_embedding_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/vre/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=embedding_model[1],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top k notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac413b3243e9474daf749b95401eeebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 3\n",
    "# Call the retrieve method to retrieve the top 10 documents for a given query\n",
    "query = \"congestion control\"\n",
    "retrieved_docs = retriever.retrieve(query=query, top_k=k*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'docid': 'NB_3a14cad6ff19be08786f76a00ad5ba569d36449caf98b6babfe6d6e894720b34', 'score': 0.9766805911160776}, {'docid': 'NB_78dbea99683329571780ec1a9c6707fa189c2a5743af22c9dd72c8282921c34b', 'score': 0.9765680264825364}, {'docid': 'NB_7560bc963f57d6df336e1e9df37505293c8d027bc85914aee8b1d9c9e2a0c8e0', 'score': 0.9764630409584535}]\n"
     ]
    }
   ],
   "source": [
    "docids = []\n",
    "scores = []\n",
    "for doc in retrieved_docs: \n",
    "    docids.append(doc.meta['name'])\n",
    "    scores.append(doc.score)\n",
    "\n",
    "# Create a sample dataframe\n",
    "df = pd.DataFrame({'docid': docids, 'score': scores})\n",
    "\n",
    "# Group the scores by ID and apply max pooling\n",
    "max_pooled_scores = df.groupby('docid')['score'].max()\n",
    "\n",
    "# Sort the max pooled scores in descending order and select the top k records\n",
    "k = 3  # Set the value of k to 3 (you can change it to any number you like)\n",
    "top_k_scores = max_pooled_scores.sort_values(ascending=False).head(k)\n",
    "\n",
    "# Create a list of dictionaries to show the top k scores with their corresponding document IDs\n",
    "output_list = []\n",
    "for docid, score in top_k_scores.items():\n",
    "    output_dict = {'docid': docid, 'score': score}\n",
    "    output_list.append(output_dict)\n",
    "\n",
    "# Output the top k scores with their corresponding document IDs as a list of dictionaries\n",
    "print(output_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docid\n",
       "NB_3a14cad6ff19be08786f76a00ad5ba569d36449caf98b6babfe6d6e894720b34    0.976681\n",
       "NB_78dbea99683329571780ec1a9c6707fa189c2a5743af22c9dd72c8282921c34b    0.976568\n",
       "NB_7560bc963f57d6df336e1e9df37505293c8d027bc85914aee8b1d9c9e2a0c8e0    0.976463\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
